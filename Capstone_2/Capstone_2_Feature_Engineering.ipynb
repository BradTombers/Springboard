{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "campaign_data = pd.read_csv('campaign_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['send_date'], format = \"%d-%m-%Y %H:%M\")\n",
    "df.drop('send_date', axis = 1, inplace = True)\n",
    "df.index = df['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = min(df['date']) + pd.Timedelta(days = 115)\n",
    "train_df = df.loc[df['date'] < split_date]\n",
    "test_df = df.loc[df['date'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: 'user_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: 'user_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_df['no_of_emails'] =train_df.groupby('user_id').size()\n",
    "train_df['cumulative_count'] = train_df.groupby('user_id').cumcount()\n",
    "\n",
    "# returns timestamp object day of week and hour of day\n",
    "def weekday(a):\n",
    "    return a.dayofweek\n",
    "\n",
    "def hourofday(a):\n",
    "    return a.hour\n",
    "\n",
    "train_df['day_of_week']= train_df['date'].apply(weekday)\n",
    "train_df['hour_of_day']= train_df['date'].apply(hourofday)\n",
    "\n",
    "train_df.fillna(0, inplace = True)\n",
    "train_df.reset_index(drop = True, inplace=True)\n",
    "\n",
    "# merge campagin data with emails\n",
    "train_df = campaign_data.merge(train_df, on = 'campaign_id')\n",
    "train_df['temp'] = 1\n",
    "\n",
    "# Calculates the count received of each type of campaign - essentially whether or not they received that campaign\n",
    "pivot_df = pd.pivot_table(train_df, values=\"temp\", index=\"user_id\", columns=\"campaign_id\", aggfunc=\"count\", fill_value=0).reset_index()\n",
    "pivot_df.columns = ['user_id'] + ['campaign_' + str(col) for col in range(29,52)]\n",
    "train_df = train_df.merge(pivot_df, on = 'user_id')\n",
    "\n",
    "# Calculates the count received of each type of communication\n",
    "pivot_df = pd.pivot_table(train_df, values=\"temp\", index=\"user_id\", columns=\"communication_type\", aggfunc=\"count\", fill_value=0).reset_index()\n",
    "pivot_df.columns = ['user_id', 'conference_count', 'corporate_count','hackathon_count','newsletter_count','others_count','upcoming_events_count','webinar_count']\n",
    "train_df = train_df.merge(pivot_df, on = 'user_id')\n",
    "\n",
    "# calculate percentage of communcation type received for each user\n",
    "train_df['conference_percent']=train_df['conference_count'] / train_df['no_of_emails']\n",
    "train_df['corporate_percent']=train_df['corporate_count'] / train_df['no_of_emails']\n",
    "train_df['hackathon_percent']=train_df['hackathon_count'] / train_df['no_of_emails']\n",
    "train_df['newsletter_percent']=train_df['newsletter_count'] / train_df['no_of_emails']\n",
    "train_df['others_percent']=train_df['others_count'] / train_df['no_of_emails']\n",
    "train_df['upcoming_events_percent']=train_df['upcoming_events_count'] / train_df['no_of_emails']\n",
    "train_df['webinar_percent']=train_df['webinar_count'] / train_df['no_of_emails']\n",
    "\n",
    "# drop unneccesary columns\n",
    "train_df.drop(['temp','conference_count', 'corporate_count','hackathon_count','newsletter_count','others_count','upcoming_events_count','webinar_count'], axis = 1, inplace = True)\n",
    "\n",
    "# NLP\n",
    "vectorizer = CountVectorizer(min_df = 1)\n",
    "\n",
    "corpus = train_df['subject']\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "x.toarray()\n",
    "matrix1 = x.toarray()\n",
    "vectorizer.vocabulary_.get('harvest')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(matrix1)\n",
    "\n",
    "asd = tfidf.toarray()\n",
    "asd1 = pd.DataFrame(asd) \n",
    "features = vectorizer.get_feature_names() \n",
    "asd1.columns = features\n",
    "train_df = pd.concat((train_df,asd1), axis = 1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134438</th>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-02 12:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231024</th>\n",
       "      <td>54_231024</td>\n",
       "      <td>231024</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-01 20:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65386</th>\n",
       "      <td>52_65386</td>\n",
       "      <td>65386</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-02 12:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224491</th>\n",
       "      <td>53_224491</td>\n",
       "      <td>224491</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 22:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109939</th>\n",
       "      <td>53_109939</td>\n",
       "      <td>109939</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-06 22:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  user_id  campaign_id  is_open  is_click  \\\n",
       "user_id                                                       \n",
       "134438   52_134438   134438           52        0         0   \n",
       "231024   54_231024   231024           54        0         0   \n",
       "65386     52_65386    65386           52        0         0   \n",
       "224491   53_224491   224491           53        0         0   \n",
       "109939   53_109939   109939           53        0         0   \n",
       "\n",
       "                       date  \n",
       "user_id                      \n",
       "134438  2017-11-02 12:53:00  \n",
       "231024  2017-12-01 20:15:00  \n",
       "65386   2017-11-02 12:36:00  \n",
       "224491  2017-11-06 22:33:00  \n",
       "109939  2017-11-06 22:39:00  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: 'user_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: 'user_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_df['no_of_emails'] = test_df.groupby('user_id').size()\n",
    "test_df['cumulative_count'] = test_df.groupby('user_id').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\BradT\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "\n",
      "\n",
      "\n",
      " communication_type\n",
      "user_id       5\n",
      "Conference    1\n",
      "Newsletter    0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# returns timestamp object day of week and hour of day\n",
    "def weekday(a):\n",
    "    return a.dayofweek\n",
    "\n",
    "def hourofday(a):\n",
    "    return a.hour\n",
    "\n",
    "test_df['day_of_week']= test_df['date'].apply(weekday)\n",
    "test_df['hour_of_day']= test_df['date'].apply(hourofday)\n",
    "\n",
    "test_df.fillna(0, inplace = True)\n",
    "test_df.reset_index(drop = True, inplace=True)\n",
    "\n",
    "# merge campagin data with emails\n",
    "test_df  = campaign_data.merge(test_df, on = 'campaign_id')\n",
    "test_df['temp'] = 1\n",
    "\n",
    "\n",
    "# Calculates the count received of each type of campaign - essentially whether or not they received that campaign\n",
    "pivot_df = pd.pivot_table(test_df , values=\"temp\", index=\"user_id\", columns=\"campaign_id\", aggfunc=\"count\", fill_value=0).reset_index()\n",
    "pivot_df.columns = ['user_id'] + ['campaign_' + str(col) for col in range(52,55)]\n",
    "test_df  = test_df.merge(pivot_df, on = 'user_id')\n",
    "\n",
    "\n",
    "# Calculates the count received of each type of communication\n",
    "pivot_df = pd.pivot_table(test_df, values=\"temp\", index=\"user_id\", columns=\"communication_type\", aggfunc=\"count\", fill_value=0).reset_index()\n",
    "print('here\\n\\n\\n\\n',pivot_df.iloc[0])\n",
    "pivot_df.columns = ['user_id', 'conference_count', 'newsletter_count']\n",
    "test_df = test_df.merge(pivot_df, on = 'user_id')\n",
    "\n",
    "# calculate percentage of communcation type received for each user\n",
    "test_df['conference_percent']=test_df['conference_count'] / test_df['no_of_emails']\n",
    "#test_df['corporate_percent']=test_df['corporate_count'] / test_df['no_of_emails']\n",
    "#test_df['hackathon_percent']=test_df['hackathon_count'] / test_df['no_of_emails']\n",
    "test_df['newsletter_percent']=test_df['newsletter_count'] / test_df['no_of_emails']\n",
    "#test_df['others_percent']=test_df['others_count'] / test_df['no_of_emails']\n",
    "#test_df['upcoming_events_percent']=test_df['upcoming_events_count'] / test_df['no_of_emails']\n",
    "#test_df['webinar_percent']=test_df['webinar_count'] / test_df['no_of_emails']\n",
    "\n",
    "# drop unneccesary columns\n",
    "test_df.drop(['temp','conference_count', 'newsletter_count'], axis = 1, inplace = True)\n",
    "\n",
    "# NLP\n",
    "vectorizer = CountVectorizer(min_df = 1)\n",
    "\n",
    "corpus = test_df['subject']\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "x.toarray()\n",
    "matrix1 = x.toarray()\n",
    "vectorizer.vocabulary_.get('harvest')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(matrix1)\n",
    "\n",
    "asd = tfidf.toarray()\n",
    "asd1 = pd.DataFrame(asd) \n",
    "features = vectorizer.get_feature_names() \n",
    "asd1.columns = features\n",
    "test_df  = pd.concat((test_df ,asd1), axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['communication_type','email_body','subject','email_url'], axis = 1, inplace = True)\n",
    "test_df.drop(['communication_type','email_body','subject','email_url'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('date', axis = 1, inplace = True)\n",
    "test_df.drop('date', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761657, 168)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261534, 52)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023191, 6)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023191"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "761657 + 261534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(set(test_df.columns) - set(train_df.columns))\n",
    "test_df.drop(to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(set(train_df.columns) - set(test_df.columns))\n",
    "train_df.drop(to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761657, 34)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261534, 34)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>no_of_emails</th>\n",
       "      <th>cumulative_count</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>conference_percent</th>\n",
       "      <th>newsletter_percent</th>\n",
       "      <th>2017</th>\n",
       "      <th>and</th>\n",
       "      <th>artificial</th>\n",
       "      <th>datahack</th>\n",
       "      <th>days</th>\n",
       "      <th>go</th>\n",
       "      <th>hackathons</th>\n",
       "      <th>in</th>\n",
       "      <th>india</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>just</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>new</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>now</th>\n",
       "      <th>register</th>\n",
       "      <th>summit</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>104</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>53_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.262929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>54_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>52_65386</td>\n",
       "      <td>65386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>52_32415</td>\n",
       "      <td>32415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id  total_links  no_of_internal_links  no_of_images  \\\n",
       "0           52           67                    62            10   \n",
       "1           53          104                   100            13   \n",
       "2           54           63                    58             8   \n",
       "3           52           67                    62            10   \n",
       "4           52           67                    62            10   \n",
       "\n",
       "   no_of_sections         id  user_id  is_open  is_click  no_of_emails  \\\n",
       "0               4  52_134438   134438        0         0             3   \n",
       "1               1  53_134438   134438        0         0             3   \n",
       "2               4  54_134438   134438        0         0             3   \n",
       "3               4   52_65386    65386        0         0             1   \n",
       "4               4   52_32415    32415        0         0             2   \n",
       "\n",
       "   cumulative_count  day_of_week  hour_of_day  conference_percent  \\\n",
       "0                 0            3           12            0.333333   \n",
       "1                 1            0           23            0.333333   \n",
       "2                 2            4           20            0.333333   \n",
       "3                 0            3           12            0.000000   \n",
       "4                 0            3           13            0.500000   \n",
       "\n",
       "   newsletter_percent      2017       and  artificial  datahack      days  \\\n",
       "0            0.666667  0.268543  0.268543    0.000000  0.268543  0.000000   \n",
       "1            0.666667  0.000000  0.000000    0.262929  0.000000  0.262929   \n",
       "2            0.666667  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "3            1.000000  0.268543  0.268543    0.000000  0.268543  0.000000   \n",
       "4            0.500000  0.268543  0.268543    0.000000  0.268543  0.000000   \n",
       "\n",
       "         go  hackathons        in     india  intelligence      just  learning  \\\n",
       "0  0.000000    0.268543  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
       "1  0.262929    0.000000  0.262929  0.262929      0.262929  0.262929  0.262929   \n",
       "2  0.000000    0.000000  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
       "3  0.000000    0.268543  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
       "4  0.000000    0.268543  0.000000  0.000000      0.000000  0.000000  0.000000   \n",
       "\n",
       "    machine       new  newsletter       now  register    summit        to  \n",
       "0  0.000000  0.268543    0.268543  0.000000  0.000000  0.268543  0.000000  \n",
       "1  0.262929  0.000000    0.000000  0.262929  0.262929  0.000000  0.262929  \n",
       "2  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.268543    0.268543  0.000000  0.000000  0.268543  0.000000  \n",
       "4  0.000000  0.268543    0.268543  0.000000  0.000000  0.268543  0.000000  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_export.csv\", index = False)\n",
    "test_df.to_csv(\"test_export.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
